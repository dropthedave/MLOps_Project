{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('Data/DelayedFlights.csv', index_col=[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Target Feature\n",
    "\n",
    "Since only predicting cancelled flights would be highly imbalanced (0.03%) we will modify our binary classification task to the following task\n",
    "\n",
    "- **Predicting if a flight gets *cancelled* or *diverted***\n",
    "\n",
    "This will increase the minority class from 633 (0.03%) to 8387 (0.43%) samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cancelled Flights')\n",
    "print(f'cancelled flights (absolute): {dataframe.Cancelled.value_counts().loc[1]}')\n",
    "print(f'cancelled flights (relative): {dataframe.Cancelled.value_counts(normalize=True).loc[1]}')\n",
    "print('\\nDiverted Flights')\n",
    "print(f'diverted flights (absolute): {dataframe.Diverted.value_counts().loc[1]}')\n",
    "print(f'diverted flights (relative): {dataframe.Diverted.value_counts(normalize=True).loc[1]}')\n",
    "print('\\nCombined - Cancelled or Diverted')\n",
    "print(f'cancelled or diverted flights (absolute): {dataframe.Cancelled.value_counts().loc[1] + dataframe.Diverted.value_counts().loc[1]}')\n",
    "print(f'cancelled or diverted flights (relative): {dataframe.Cancelled.value_counts(normalize=True).loc[1] + dataframe.Diverted.value_counts(normalize=True).loc[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target feature\n",
    "dataframe['Target'] = np.where((dataframe.Cancelled == 1) | (dataframe.Diverted == 1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns Cancelled, CancellationCode and diverted\n",
    "dataframe = dataframe.drop(columns=['Cancelled', 'CancellationCode', 'Diverted'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data (quarterly/monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(dataframe=dataframe, method='quarterly'):\n",
    "    # order dataframe by month\n",
    "    dataframe = dataframe.sort_values(by='Month')\n",
    "    \n",
    "    if method == 'quarterly':\n",
    "        # split dataframe (quarterly)\n",
    "        dataframe_q1 = dataframe[dataframe.Month.isin([1,2,3])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_q2 = dataframe[dataframe.Month.isin([4,5,6])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_q3 = dataframe[dataframe.Month.isin([7,8,9])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_q4 = dataframe[dataframe.Month.isin([10,11,12])].drop(columns=['Year', 'Month'])\n",
    "\n",
    "        return dataframe_q1, dataframe_q2, dataframe_q3, dataframe_q4\n",
    "\n",
    "    elif method == 'monthly':\n",
    "        # split dataframe (monthly)\n",
    "        dataframe_m1 = dataframe[dataframe.Month.isin([1])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m2 = dataframe[dataframe.Month.isin([2])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m3 = dataframe[dataframe.Month.isin([3])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m4 = dataframe[dataframe.Month.isin([4])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m5 = dataframe[dataframe.Month.isin([5])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m6 = dataframe[dataframe.Month.isin([6])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m7 = dataframe[dataframe.Month.isin([7])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m8 = dataframe[dataframe.Month.isin([8])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m9 = dataframe[dataframe.Month.isin([9])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m10 = dataframe[dataframe.Month.isin([10])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m11 = dataframe[dataframe.Month.isin([11])].drop(columns=['Year', 'Month'])\n",
    "        dataframe_m12 = dataframe[dataframe.Month.isin([12])].drop(columns=['Year', 'Month'])\n",
    "\n",
    "        return dataframe_m1, dataframe_m2, dataframe_m3, dataframe_m4, dataframe_m5, dataframe_m6, dataframe_m7, dataframe_m8, dataframe_m9, dataframe_m10, dataframe_m11, dataframe_m12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1, Q2, Q3, Q4 = split_dataframe(dataframe=dataframe, method='quarterly')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Rows: {Q1.shape[0]}\\nColumns: {Q1.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first look at the data\n",
    "Q1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics, data types and missing values\n",
    "def dataset_infos(dataframe):\n",
    "    # descriptive statistics\n",
    "    descriptives = dataframe.describe(include='all').T\n",
    "\n",
    "    # data types column\n",
    "    descriptives.insert(loc=0, column='dtype', value=dataframe.dtypes)\n",
    "    \n",
    "    # missing values\n",
    "    missing = pd.concat([dataframe.isnull().sum(), dataframe.eq('').sum()], keys=['nulls','empty strings'], axis=1)\n",
    "    \n",
    "    return pd.merge(descriptives, missing, left_index=True, right_index=True)\n",
    "\n",
    "dataset_infos(Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate rows\n",
    "print(f'Duplicated Rows: {Q1.duplicated().sum()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = Q1.drop(columns=['Target']), Q1['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, stratify=y,random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataframe):\n",
    "  '''\n",
    "  Preprocessing function\n",
    "  Input: dataframe\n",
    "  Output: transformed data\n",
    "  '''\n",
    "\n",
    "  # get features and label dtype\n",
    "  col_names = list(dataframe.columns)\n",
    "  numeric_features = list(dataframe.select_dtypes(include = np.number).columns)\n",
    "  categorical_features = list(dataframe.select_dtypes(exclude = np.number).columns)\n",
    "\n",
    "  # if not ordinal encoder in global variables\n",
    "  if not 'ordenc' in globals():\n",
    "    global ordenc\n",
    "    ordenc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "    dataframe[categorical_features] = ordenc.fit_transform(dataframe[categorical_features])\n",
    "    print('Ordinal Encoder - fit & transform...')\n",
    "  else:\n",
    "    dataframe[categorical_features] = ordenc.transform(dataframe[categorical_features])\n",
    "    print('Ordinal Encoder - transform...')\n",
    "\n",
    "  if not 'stdsc' in globals():\n",
    "    global stdsc\n",
    "    stdsc = StandardScaler()\n",
    "    dataframe = stdsc.fit_transform(dataframe)\n",
    "    print('Standard Scaler - fit & transform...')\n",
    "  else:\n",
    "    dataframe = stdsc.transform(dataframe)\n",
    "    print('Standard Scaler - transform...')\n",
    "\n",
    "  # convert back to dataframe\n",
    "  dataframe = pd.DataFrame(dataframe, columns=col_names)\n",
    "\n",
    "  # impute missing values\n",
    "  dataframe_preprocessed = dataframe.fillna(dataframe.median())\n",
    "\n",
    "  return dataframe_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_prepro = preprocessing(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_prepro = preprocessing(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2_prepro, Q2_y = preprocessing(Q2.drop(columns=['Target'])), Q2['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3_prepro, Q3_y = preprocessing(Q3.drop(columns=['Target'])), Q3['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4_prepro, Q4_y = preprocessing(Q4.drop(columns=['Target'])), Q4['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit prediction model on train dataset\n",
    "lr = LogisticRegression(random_state=420)\n",
    "lr.fit(xtrain_prepro, ytrain)\n",
    "ypred = lr.predict(xtest_prepro)\n",
    "print(f'Test accuracy on normal dataset: {accuracy_score(ytest, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    }\n",
    "# define grid search\n",
    "grid = GridSearchCV(LogisticRegression(random_state=420), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# fit grid search\n",
    "grid.fit(xtrain_prepro, ytrain)\n",
    "# best score\n",
    "print(f'Best score: {grid.best_score_}')\n",
    "# best estimator\n",
    "print(f'Best estimator: {grid.best_estimator_}')\n",
    "# best parameters\n",
    "print(f'Best parameters: {grid.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit prediction model on train dataset (gridsearch params)\n",
    "lr = LogisticRegression(**grid.best_params_, random_state=420)\n",
    "lr.fit(xtrain_prepro, ytrain)\n",
    "ypred = lr.predict(xtest_prepro)\n",
    "print(f'Test accuracy on normal dataset: {accuracy_score(ytest, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "ypred = lr.predict(Q2_prepro)\n",
    "print(f'Accuracy on Quartal2 dataset: {accuracy_score(Q2_y, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "ypred = lr.predict(Q3_prepro)\n",
    "print(f'Accuracy on Quartal3 dataset: {accuracy_score(Q3_y, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4\n",
    "ypred = lr.predict(Q4_prepro)\n",
    "print(f'Accuracy on Quartal4 dataset: {accuracy_score(Q4_y, ypred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('Data/sensor.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop sensor_15\n",
    "dataframe = dataframe.drop(columns=['sensor_15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split timestamp column into year, month, day (int)\n",
    "dataframe['Year'] = dataframe['timestamp'].str[:4].astype(int)\n",
    "dataframe['Month'] = dataframe['timestamp'].str[5:7].astype(int)\n",
    "dataframe['Day'] = dataframe['timestamp'].str[8:10].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(dataframe=dataframe):\n",
    "    # order dataframe by month\n",
    "    dataframe = dataframe.sort_values(by='Month')\n",
    "    \n",
    "    # split dataframe (monthly)\n",
    "    dataframe_04 = dataframe[dataframe.Month.isin([4])].drop(columns=['Year', 'Month', 'timestamp'])\n",
    "    dataframe_05 = dataframe[dataframe.Month.isin([5])].drop(columns=['Year', 'Month', 'timestamp'])\n",
    "    dataframe_06 = dataframe[dataframe.Month.isin([6])].drop(columns=['Year', 'Month', 'timestamp'])\n",
    "    dataframe_07 = dataframe[dataframe.Month.isin([7])].drop(columns=['Year', 'Month', 'timestamp'])\n",
    "    dataframe_08 = dataframe[dataframe.Month.isin([8])].drop(columns=['Year', 'Month', 'timestamp'])\n",
    "\n",
    "    return dataframe_04, dataframe_05, dataframe_06, dataframe_07, dataframe_08\n",
    "\n",
    "df_04, df_05, df_06, df_07, df_08 = split_dataframe(dataframe=dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df_04.drop(columns=['machine_status']), df_04['machine_status']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, stratify=y,random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_prepro, ytrain = preprocessing(xtrain), le.fit_transform(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_prepro, ytest = preprocessing(xtest), le.transform(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_04\n",
    "df_04_prepro, df_04_y = preprocessing(df_04.drop(columns=['machine_status'])), le.transform(df_04['machine_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_05\n",
    "df_05_prepro, df_05_y = preprocessing(df_05.drop(columns=['machine_status'])), le.transform(df_05['machine_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_06\n",
    "df_06_prepro, df_06_y = preprocessing(df_06.drop(columns=['machine_status'])), le.transform(df_06['machine_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_07\n",
    "df_07_prepro, df_07_y = preprocessing(df_07.drop(columns=['machine_status'])), le.transform(df_07['machine_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_08\n",
    "df_08_prepro, df_08_y = preprocessing(df_08.drop(columns=['machine_status'])), le.transform(df_08['machine_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit prediction model on train dataset\n",
    "lr = RandomForestClassifier(random_state=420)\n",
    "lr.fit(xtrain_prepro, ytrain)\n",
    "ypred = lr.predict(xtest_prepro)\n",
    "print(f'Test accuracy on normal dataset: {accuracy_score(ytest, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    }\n",
    "# define grid search\n",
    "grid = GridSearchCV(LogisticRegression(random_state=420), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# fit grid search\n",
    "grid.fit(xtrain_prepro, ytrain)\n",
    "# best score\n",
    "print(f'Best score: {grid.best_score_}')\n",
    "# best estimator\n",
    "print(f'Best estimator: {grid.best_estimator_}')\n",
    "# best parameters\n",
    "print(f'Best parameters: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit prediction model on train dataset (gridsearch params)\n",
    "lr = LogisticRegression(**grid.best_params_, random_state=420)\n",
    "lr.fit(xtrain_prepro, ytrain)\n",
    "ypred = lr.predict(xtest_prepro)\n",
    "print(f'Test accuracy on normal dataset: {accuracy_score(ytest, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_04\n",
    "ypred = lr.predict(df_04_prepro)\n",
    "print(f'Accuracy on Quartal2 dataset: {accuracy_score(df_04_y, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_05\n",
    "ypred = lr.predict(df_05_prepro)\n",
    "print(f'Accuracy on Quartal2 dataset: {accuracy_score(df_05_y, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_06\n",
    "ypred = lr.predict(df_06_prepro)\n",
    "print(f'Accuracy on Quartal2 dataset: {accuracy_score(df_06_y, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_07\n",
    "ypred = lr.predict(df_07_prepro)\n",
    "print(f'Accuracy on Quartal2 dataset: {accuracy_score(df_07_y, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_08\n",
    "# ypred = lr.predict(df_08_prepro)\n",
    "# print(f'Accuracy on Quartal2 dataset: {accuracy_score(df_08_y, ypred)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Smoke Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('Data/smoke_detection_iot.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function split dataframe into 3 parts (ordered by UTC)\n",
    "def split_dataframe(dataframe):\n",
    "    # order dataframe by UTC\n",
    "    dataframe = dataframe.sort_values(by='UTC')\n",
    "    \n",
    "    # split dataframe into 3 equal parts\n",
    "    dataframe_1 = dataframe.iloc[:int(dataframe.shape[0]/3)]\n",
    "    dataframe_2 = dataframe.iloc[int(dataframe.shape[0]/3):int(dataframe.shape[0]/3)*2]\n",
    "    dataframe_3 = dataframe.iloc[int(dataframe.shape[0]/3)*2:]\n",
    "\n",
    "    return dataframe_1, dataframe_2, dataframe_3\n",
    "\n",
    "df_1, df_2, df_3 = split_dataframe(dataframe=dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df_1.drop(columns=['Fire Alarm']), df_1['Fire Alarm']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, stratify=y,random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Encoder - fit & transform...\n",
      "Standard Scaler - fit & transform...\n"
     ]
    }
   ],
   "source": [
    "xtrain_prepro = preprocessing(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Encoder - transform...\n",
      "Standard Scaler - transform...\n"
     ]
    }
   ],
   "source": [
    "xtest_prepro = preprocessing(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Encoder - transform...\n",
      "Standard Scaler - transform...\n"
     ]
    }
   ],
   "source": [
    "df_1_prepro, df_1_y = preprocessing(df_1.drop(columns=['Fire Alarm'])), df_1['Fire Alarm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Encoder - transform...\n",
      "Standard Scaler - transform...\n"
     ]
    }
   ],
   "source": [
    "df_2_prepro, df_2_y = preprocessing(df_2.drop(columns=['Fire Alarm'])), df_2['Fire Alarm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Encoder - transform...\n",
      "Standard Scaler - transform...\n"
     ]
    }
   ],
   "source": [
    "df_3_prepro, df_3_y = preprocessing(df_3.drop(columns=['Fire Alarm'])), df_3['Fire Alarm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on normal dataset: 0.9997605363984674\n"
     ]
    }
   ],
   "source": [
    "# fit prediction model on train dataset\n",
    "lr = RandomForestClassifier(random_state=420)\n",
    "lr.fit(xtrain_prepro, ytrain)\n",
    "ypred = lr.predict(xtest_prepro)\n",
    "print(f'Test accuracy on normal dataset: {accuracy_score(ytest, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on normal dataset: 0.8523184518106917\n"
     ]
    }
   ],
   "source": [
    "# df_2\n",
    "ypred = lr.predict(df_2_prepro)\n",
    "print(f'Test accuracy on normal dataset: {accuracy_score(df_2_y, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on normal dataset: 0.7291407222914073\n"
     ]
    }
   ],
   "source": [
    "# df_3\n",
    "ypred = lr.predict(df_3_prepro)\n",
    "print(f'Test accuracy on normal dataset: {accuracy_score(df_3_y, ypred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
