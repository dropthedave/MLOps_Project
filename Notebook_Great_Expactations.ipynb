{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Operations Project\n",
    "The aim of the project is to simulate the realworld process of deploying machine learning models, using the concepts that we have discussed during the classes. This notebook is focuses on the implementation of ``Great Expectations`` with a connected user interface (UI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "**UTC**:\n",
    "Timestamp UTC seconds\n",
    "\n",
    "**Temperature[C]**:\n",
    "Air Temperature\n",
    "\n",
    "**Humidity[%]**:\n",
    "Air Humidity\n",
    "\n",
    "**TVOC[ppb]**:\n",
    "Total Volatile Organic Compounds; measured in parts per billion\n",
    "\n",
    "**eCO2[ppm]**:\n",
    "CO2 equivalent concentration; calculated from different values like TVOC\n",
    "\n",
    "**Raw H2**:\n",
    "Raw molecular hydrogen; not compensated (Bias, temperature, etc.)\n",
    "\n",
    "**Raw Ethanol**:\n",
    "Raw ethanol gas\n",
    "\n",
    "**Pressure[hPa]**:\n",
    "Air Pressure\n",
    "\n",
    "**PM1.0**:\n",
    "Particulate matter size < 1.0 µm (PM1.0). 1.0 µm < 2.5 µm (PM2.5)\n",
    "\n",
    "**PM2.5**:\n",
    "Particulate matter size < 1.0 µm (PM1.0). 1.0 µm < 2.5 µm (PM2.5)\n",
    "\n",
    "**NC0.5**:\n",
    "Number concentration of particulate matter. This differs from PM because NC gives the actual number of particles in the air. The raw NC is also classified by the particle size: < 0.5 µm (NC0.5); 0.5 µm < 1.0 µm (NC1.0); 1.0 µm < 2.5 µm (NC2.5);\n",
    "\n",
    "**NC1.0**:\n",
    "Number concentration of particulate matter. This differs from PM because NC gives the actual number of particles in the air. The raw NC is also classified by the particle size: < 0.5 µm (NC0.5); 0.5 µm < 1.0 µm (NC1.0); 1.0 µm < 2.5 µm (NC2.5);\n",
    "\n",
    "**NC2.5**:\n",
    "Number concentration of particulate matter. This differs from PM because NC gives the actual number of particles in the air. The raw NC is also classified by the particle size: < 0.5 µm (NC0.5); 0.5 µm < 1.0 µm (NC1.0); 1.0 µm < 2.5 µm (NC2.5);\n",
    "\n",
    "**CNT**:\n",
    "Sample counter\n",
    "\n",
    "**Fire Alarm (Target)**:\n",
    "Ground truth is \"1\" if a fire is there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "# import great_expectations.jupyter_ux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('Data/smoke_detection.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(dataframe: pd.DataFrame, output_filenames: list) -> None:\n",
    "    # Order dataframe by month\n",
    "    dataframe = dataframe.sort_values(by='UTC').reset_index(drop=True)\n",
    "\n",
    "    # Split dataframe into 3 equal-sized datasets\n",
    "    size = len(dataframe)\n",
    "    third = size // 3\n",
    "\n",
    "    # Split the dataframe\n",
    "    dataframe_1 = dataframe.iloc[:third]\n",
    "    dataframe_2 = dataframe.iloc[third:third*2]\n",
    "    dataframe_3 = dataframe.iloc[third*2:]\n",
    "\n",
    "    # Save each split dataframe as a CSV file\n",
    "    for df, filename in zip([dataframe_1, dataframe_2, dataframe_3], output_filenames):\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "# Apply function\n",
    "split_dataframe(dataframe, ['df_one.csv', 'df_two.csv', 'df_three.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: #FE6C1B;\">Great Expectations</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminologies\n",
    "\n",
    "*Context*: A context in is the main object that manages the overall configuration and execution of the data expectations. It serves as a container for storing and organizing expectations, data sources, and validation results. The context allows to define, execute, and manage our data expectations.\n",
    "\n",
    "*Validator*: A validator is responsible for evaluating expectations on a given batch of data. Validators are used to validate data against a set of predefined expectations. They help to assess data quality, perform data validation, and monitor data pipelines.\n",
    "\n",
    "*Suite*: An Expectation Suite is a collection of expectations that define the desired properties and characteristics of our data. It serves as a set of rules against which your data can be validated. The suite contains a set of expectations that can be applied to one or more batches of data. \n",
    "\n",
    "*Batch*: A batch represents a subset of data that we want to evaluate against our expectations. It can be a collection of rows, a partitioned dataset, a file, a table, or any other logical grouping of data. Batches are used as inputs to validation processes and contain the data you want to validate.\n",
    "\n",
    "*Checkpoint*: A Checkpoint is a way to operationalize data validation using Expectation Suites. It allows you to define a pipeline-like flow for performing data validation on batches of data. It helps automate the validation process by defining the steps to be executed on data batches and tracking the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "- Open Anaconda Prompt Terminal\n",
    "- After satisfying ``!pip install great_expectations``, run ``great_expectations init`` and confirm with 'Y'\n",
    "- Verify the installation by running the version ``!great_expectations --version``\n",
    "- Our version used: version 0.16.13\n",
    "\n",
    "\n",
    "More information: https://docs.greatexpectations.io/docs/tutorials/quickstart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After setting up great_expectations init\n",
    "for i in os.listdir('/Users/jlutt/great_expectations'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "import great_expectations as gx\n",
    "from great_expectations.checkpoint import SimpleCheckpoint\n",
    "\n",
    "# Create data context\n",
    "context = gx.get_context(\n",
    "    context_root_dir='/Users/jlutt/great_expectations'\n",
    ")\n",
    "\n",
    "# Connect to data\n",
    "validator = context.sources.pandas_default.read_csv(\"df_one.csv\")\n",
    "\n",
    "# Extract column names\n",
    "column_names = [f\"{column_name}\" for column_name in validator.columns()]\n",
    "print(f\"Columns: {', '.join(column_names)}.\")\n",
    "print(validator.head(n_rows=5, fetch_all=False))\n",
    "\n",
    "# Create expectation suite\n",
    "expectation_suite_name = \"smoke_detection_suite\"\n",
    "suite = context.create_expectation_suite(expectation_suite_name=expectation_suite_name,overwrite_existing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectations\n",
    "Now we use that data source for profiling, validation and documentation. More information regarding expectations, can be found here: https://legacy.docs.greatexpectations.io/en/latest/reference/glossary_of_expectations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Validator to create and run an Expectation\n",
    "# Assert column count\n",
    "validator.expect_table_column_count_to_equal(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert data types\n",
    "validator.expect_column_values_to_be_of_type(\"UTC\", \"int64\")\n",
    "validator.expect_column_values_to_be_of_type(\"Temperature[C]\", \"float\")\n",
    "validator.expect_column_values_to_be_of_type(\"Humidity[%]\", \"float\")\n",
    "validator.expect_column_values_to_be_of_type(\"TVOC[ppb]\", \"int64\")\n",
    "validator.expect_column_values_to_be_of_type(\"eCO2[ppm]\", \"int64\")\n",
    "validator.expect_column_values_to_be_of_type(\"Raw H2\", \"int64\")\n",
    "validator.expect_column_values_to_be_of_type(\"Raw Ethanol\", \"int64\")\n",
    "validator.expect_column_values_to_be_of_type(\"Pressure[hPa]\", \"float\")\n",
    "validator.expect_column_values_to_be_of_type(\"PM1.0\", \"float\")\n",
    "validator.expect_column_values_to_be_of_type(\"PM2.5\", \"float\")\n",
    "validator.expect_column_values_to_be_of_type(\"NC0.5\", \"float\")\n",
    "validator.expect_column_values_to_be_of_type(\"NC1.0\", \"float\")\n",
    "validator.expect_column_values_to_be_of_type(\"NC2.5\", \"float\")\n",
    "validator.expect_column_values_to_be_of_type(\"CNT\", \"int64\")\n",
    "validator.expect_column_values_to_be_of_type(\"Fire Alarm\", \"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Assert no missing values\n",
    "for column_name in column_names:\n",
    "    validator.expect_column_values_to_not_be_null(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert relationships between columns\n",
    "validator.expect_column_pair_values_A_to_be_greater_than_B(\"PM2.5\", \"PM1.0\").success = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert target variable\n",
    "validator.expect_column_values_to_be_in_set(\"Fire Alarm\", [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert value ranges to detect outliers\n",
    "validator.expect_column_values_to_be_between(\"Temperature[C]\", min_value=-23, max_value=60)\n",
    "validator.expect_column_values_to_be_between(\"Humidity[%]\", min_value=10, max_value=76)\n",
    "validator.expect_column_values_to_be_between(\"TVOC[ppb]\", min_value=0, max_value=None)\n",
    "validator.expect_column_values_to_be_between(\"eCO2[ppm]\", min_value=0, max_value=None)\n",
    "validator.expect_column_values_to_be_between(\"Pressure[hPa]\", min_value=930, max_value=941)\n",
    "validator.expect_column_values_to_be_between(\"PM1.0\", min_value=0, max_value=None)\n",
    "validator.expect_column_values_to_be_between(\"PM2.5\", min_value=0, max_value=None)\n",
    "validator.expect_column_values_to_be_between(\"NC0.5\", min_value=0, max_value=None)\n",
    "validator.expect_column_values_to_be_between(\"NC1.0\", min_value=0, max_value=None)\n",
    "validator.expect_column_values_to_be_between(\"NC2.5\", min_value=0, max_value=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great Expectations UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review and save our expectation suite\n",
    "print(validator.get_expectation_suite(discard_failed_expectations=False))\n",
    "validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "\n",
    "# Create checkpoint\n",
    "checkpoint = SimpleCheckpoint(\n",
    "    \"smoke_detection_checkpoint\",\n",
    "    context,\n",
    "    validator=validator,\n",
    ")\n",
    "\n",
    "# Run checkpoint to validate data \n",
    "checkpoint_result = checkpoint.run()\n",
    "\n",
    "# View results\n",
    "context.build_data_docs()\n",
    "validation_result_identifier = checkpoint_result.list_validation_result_identifiers()[0]\n",
    "context.open_data_docs(resource_identifier=validation_result_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://medium.com/@mostsignificant/python-data-validation-made-easy-with-the-great-expectations-package-8d1be266fd3f\n",
    "- https://towardsdatascience.com/great-expectations-automated-testing-for-data-science-and-engineering-teams-1e7c78f1d2d5\n",
    "- https://towardsdatascience.com/a-great-python-library-great-expectations-6ac6d6fe822e\n",
    "- https://github.com/datarootsio/tutorial-great-expectations/blob/main/tutorial_great_expectations.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
